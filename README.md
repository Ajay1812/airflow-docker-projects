# Airflow Docker Projects

Welcome to the **Airflow Docker Projects** repository! ğŸš€ This repository contains multiple projects that demonstrate the usage of **Apache Airflow** with **Docker** to orchestrate workflows efficiently.

## ğŸ“Œ Overview

This repository provides hands-on projects that showcase different aspects of Apache Airflow, including DAGs, task dependencies, scheduling, and integrations with various tools. All projects are located inside the `dags/` folder.

## ğŸ“‚ Projects Included

Below is a list of projects available in this repository:

1. **ETL Manga Data** (`ETL_manga_data.py`)

   - Extracts, transforms, and loads manga-related data.
   - Uses external data sources for scraping.

2. **ETL Toll Data** (`ETL_toll_data.py`)

   - Processes toll data from various sources.
   - Converts and stores data in structured formats.

3. **ETL Toll Python** (`ETL_toll_python.py`)

   - Another implementation of toll data processing.
   - Demonstrates alternative ETL approaches.

4. **ETL Web Server Log** (`etl_web_server_log.py`)

   - Parses web server logs for insights.
   - Stores and processes log data for analysis.

5. **Final Assignment** (`finalassignment/`)
   - Contains multiple ETL scripts for toll data.
   - Includes extracted datasets and structured output.

## ğŸ—ï¸ Prerequisites

Before running the projects, ensure you have the following installed:

- **Docker** (latest version recommended)
- **Docker Compose**
- **Python 3.7+** (if required for additional configurations)

## ğŸš€ Getting Started

### Clone the Repository

```bash
git clone https://github.com/Ajay1812/airflow-docker-projects.git
cd airflow-docker-projects
```

### Start the Airflow Environment

Each project is included as a DAG inside the `dags/` folder. To start the environment, run:

```bash
docker-compose up -d
```

This will pull the necessary images and start the Airflow web server, scheduler, and workers.

### Access the Airflow UI

Once the services are up, you can access the **Airflow Web UI** at:

```
http://localhost:8080
```

Default credentials:

- **Username:** `airflow`
- **Password:** `airflow`

## ğŸ› ï¸ Project Structure

```plaintext
â”œâ”€â”€ dags/                  # Contains all Airflow DAGs (projects)
â”‚   â”œâ”€â”€ ETL_manga_data.py  # DAG for manga data ETL
â”‚   â”œâ”€â”€ ETL_toll_data.py   # DAG for toll data processing
â”‚   â”œâ”€â”€ ETL_toll_python.py # Alternative toll data ETL approach
â”‚   â”œâ”€â”€ etl_web_server_log.py # DAG for web server log analysis
â”‚   â”œâ”€â”€ config.py          # Configuration file for DAGs
â”‚   â”œâ”€â”€ data/              # Folder containing extracted data
â”‚   â”œâ”€â”€ finalassignment/   # Additional ETL scripts & extracted data
â”‚   â”œâ”€â”€ manga_scrapper/    # Additional script for manga scrapper
â”œâ”€â”€ plugins/               # Custom operators and hooks
â”œâ”€â”€ docker-compose.yml     # Docker configuration
â””â”€â”€ README.md              # Main repository documentation
```

## ğŸ”§ Customization

- Modify the **DAGs** inside the `dags/` directory to create your own workflows.
- Extend the **Docker Compose** file to include additional services such as databases, message queues, or APIs.
- Configure environment variables in `.env` files if required.

## ğŸ“œ License

This repository is licensed under the **MIT License**. Feel free to use and modify the projects as needed.

## ğŸ¤ Contributing

Contributions are welcome! If you find a bug or want to enhance a project, feel free to submit a pull request.

## ğŸ“¬ Contact

For any queries, reach out to:
ğŸ“§ Email: [a.kumar01c@gmail.com]
ğŸ”— GitHub: [https://github.com/Ajay1812]

Happy Coding! ğŸ‰
